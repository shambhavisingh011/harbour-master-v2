---
# 1. Install Software & Dependencies
- name: "Install MariaDB Server and Galera dependencies"
  apt:
    name:
      - mariadb-server
      - mariadb-client
      - mariadb-backup
      - python3-pymysql
      - socat
      - rsync
    state: present
    update_cache: yes
  become: yes

# 2. Pre-Check: Detect Current Cluster State
# This allows us to skip bootstrap/init tasks if the cluster is already healthy
- name: "PRE-CHECK: Check if MariaDB is already running and synced"
  shell: |
    if ! systemctl is-active --quiet mariadb; then
      echo "OFFLINE"
    else
      # Check if we can log in and see the state
      PASS="{{ wsrep_sst_auth.split(':')[1] }}"
      STATUS=$(mariadb -u root -p"$PASS" -N -s -e "SHOW STATUS LIKE 'wsrep_local_state_comment';" 2>/dev/null | awk '{print $2}')
      echo "${STATUS:-LOCKED}"
    fi
  become: yes
  register: cluster_precheck
  changed_when: false
  failed_when: false

# 3. Prevent Standalone Conflict
- name: "Stop MariaDB to prevent standalone mode conflicts"
  service:
    name: mariadb
    state: stopped
  become: yes
  # Only stop if it's not already part of a healthy cluster
  when: cluster_precheck.stdout != "Synced"

- name: "Disable default bind-address in 50-server.cnf"
  lineinfile:
    path: /etc/mysql/mariadb.conf.d/50-server.cnf
    regexp: '^bind-address'
    line: '#bind-address = 0.0.0.0'
  become: yes

# 4. Configure Node
- name: "Deploy Galera Configuration"
  template:
    src: galera.cnf.j2
    dest: /etc/mysql/mariadb.conf.d/60-galera.cnf
    owner: root
    group: root
    mode: '0644'
  become: yes
  register: config_deployed

# 5. Initialization & Bootstrap Preparation
- name: "Initialize MariaDB data directory if empty"
  command: mariadb-install-db --user=mysql --basedir=/usr --datadir=/var/lib/mysql
  args:
    creates: /var/lib/mysql/mysql
  become: yes

- name: "Check if grastate.dat exists"
  stat:
    path: /var/lib/mysql/grastate.dat
  register: grastate_file

# 6. Handle Cluster Bootstrap logic (Primary Node)
- name: "Bootstrap logic for Primary Node (Node 01)"
  block:
    - name: "Set safe_to_bootstrap flag in grastate.dat"
      lineinfile:
        path: /var/lib/mysql/grastate.dat
        regexp: '^safe_to_bootstrap: 0'
        line: 'safe_to_bootstrap: 1'
      when: 
        - grastate_file.stat.exists
        - cluster_precheck.stdout != "Synced"

    - name: "Execute Galera New Cluster command"
      command: galera_new_cluster
      when: cluster_precheck.stdout != "Synced"

    - name: "Wait for Primary Node to be ready"
      wait_for:
        port: 3306
        timeout: 60
      when: cluster_precheck.stdout != "Synced"
  become: yes
  when: inventory_hostname == groups['galera'][0]

# 7. Join Secondary Nodes with Recovery Logic
- name: "Join Secondary Nodes to Cluster"
  service:
    name: mariadb
    state: started
  become: yes
  when: 
    - inventory_hostname != groups['galera'][0]
    - cluster_precheck.stdout != "Synced"
  throttle: 1
  register: node_join
  ignore_errors: yes

- name: "RECOVERY: Wipe corrupted state if Join failed"
  file:
    path: "/var/lib/mysql/{{ item }}"
    state: absent
  become: yes
  loop:
    - grastate.dat
    - galera.cache
  when: 
    - inventory_hostname != groups['galera'][0]
    - cluster_precheck.stdout != "Synced"
    - node_join is failed

- name: "RETRY: Start MariaDB after state wipe"
  service:
    name: mariadb
    state: started
  become: yes
  when: 
    - inventory_hostname != groups['galera'][0]
    - cluster_precheck.stdout != "Synced"
    - node_join is failed

# 8. SSH & SECURITY HANDSHAKE
- name: "SSH: Ensure .ssh directory exists for root"
  file:
    path: /root/.ssh
    state: directory
    mode: '0700'
  become: yes

- name: "SSH: Authorize LVS Health Check Key"
  authorized_key:
    user: root
    state: present
    key: "{{ lookup('file', playbook_dir + '/roles/lvs/files/id_rsa.pub') }}"
  become: yes

- name: "SSH: Allow root login via key"
  lineinfile:
    path: /etc/ssh/sshd_config
    regexp: '^#?PermitRootLogin'
    line: 'PermitRootLogin prohibit-password'
  become: yes
  notify: Restart SSH

# 9. LVS-DR NETWORKING & HCIP LOGIC
- name: "LVS-DR: Add VIP to loopback interface"
  shell: "ip addr add {{ lvs_vip }}/32 dev lo || true"
  become: yes
  changed_when: false

- name: "LVS-DR: Apply ARP Suppression"
  sysctl:
    name: "{{ item.key }}"
    value: "{{ item.value }}"
    state: present
  loop:
    - { key: 'net.ipv4.conf.all.arp_ignore', value: '1' }
    - { key: 'net.ipv4.conf.all.arp_announce', value: '2' }
    - { key: 'net.ipv4.conf.lo.arp_ignore', value: '1' }
    - { key: 'net.ipv4.conf.lo.arp_announce', value: '2' }
  become: yes

- name: "HCIP: Load dummy network module"
  modprobe:
    name: dummy
    state: present
  become: yes
  when: inventory_hostname in groups['galera'][:2]

- name: "HCIP: Create dummy0 network interface"
  shell: "ip link add dummy0 type dummy || true"
  become: yes
  when: inventory_hostname in groups['galera'][:2]

- name: "HCIP: Deploy Management Script"
  template:
    src: galera_hcip_manager.sh.j2
    dest: /usr/local/bin/galera_hcip_manager.sh
    mode: '0755'
  become: yes
  notify: Restart HCIP Service

- name: "HCIP: Deploy Systemd Service Unit"
  template:
    src: galera-hcip.service.j2
    dest: /etc/systemd/system/galera-hcip.service
  become: yes
  notify: 
    - Reload Systemd         
    - Restart HCIP Service

- name: "HCIP: Remove old Cron Job"
  cron:
    name: "Galera HCIP Monitor"
    state: absent
  become: yes

- name: "HCIP: Start and Enable HCIP Service"
  systemd:
    name: galera-hcip
    state: started
    enabled: yes
  become: yes
  when: inventory_hostname in groups['galera'][:2]

# 10. Health Check & Sync Verification
- name: "[Self-Healing] Wait for Node to finish Sync"
  shell: |
    PASS="{{ wsrep_sst_auth.split(':')[1] }}"
    mariadb -u root -p"$PASS" -N -s -e "SHOW STATUS LIKE 'wsrep_local_state_comment';"
  become: yes
  register: sync_check
  until: '"Synced" in sync_check.stdout'
  retries: 40
  delay: 10
  changed_when: false
  # Skip if we already confirmed it was Synced in PRE-CHECK
  when: cluster_precheck.stdout != "Synced"

# 11. Users & Access Management
- name: "Create SST User for replication"
  community.mysql.mysql_user:
    name: "{{ wsrep_sst_auth.split(':')[0] }}"
    password: "{{ wsrep_sst_auth.split(':')[1] }}"
    priv: "*.*:ALL"
    state: present
    host: "%"
    login_user: root
    login_password: "{{ wsrep_sst_auth.split(':')[1] }}"
    login_unix_socket: /var/run/mysqld/mysqld.sock
    check_implicit_admin: yes
  become: yes
  run_once: true

- name: "Allow Root Access from Remote Network"
  community.mysql.mysql_user:
    name: root
    host: "{{ item }}"
    password: "{{ wsrep_sst_auth.split(':')[1] }}"
    priv: "*.*:ALL,GRANT"
    state: present
    login_user: root
    login_password: "{{ wsrep_sst_auth.split(':')[1] }}"
    login_unix_socket: /var/run/mysqld/mysqld.sock
    check_implicit_admin: yes
  loop:
    - "%"
    - "localhost"
  become: yes
  run_once: true
