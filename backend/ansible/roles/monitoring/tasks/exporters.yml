---
- name: Install Node and MySQL Exporters
  apt:
    name:
      - prometheus-node-exporter
      - prometheus-mysqld-exporter
      - python3-pymysql
    state: present
    update_cache: yes
  become: yes

- name: "[Gatekeeper] Check Galera Sync Status"
  shell: |
    # Using SST password as it is guaranteed to be in scope
    PASS="{{ wsrep_sst_auth.split(':')[1] }}"
    if mariadb -u root -p"$PASS" -e "SHOW STATUS LIKE 'wsrep_local_state_comment';" | grep -q 'wsrep_local_state_comment'; then
       mariadb -u root -p"$PASS" -N -s -e "SHOW STATUS LIKE 'wsrep_local_state_comment';" | awk '{print $2}'
    else
       echo "Standalone"
    fi
  become: yes
  register: cluster_status
  until: cluster_status.stdout == "Synced" or cluster_status.stdout == "Standalone"
  retries: 10
  delay: 5
  ignore_errors: yes

- name: "[Recovery] Force Bootstrap on db-01 if stuck"
  shell: |
    PASS="{{ wsrep_sst_auth.split(':')[1] }}"
    mariadb -u root -p"$PASS" -e "SET GLOBAL wsrep_provider_options='pc.bootstrap=YES';"
  become: yes
  when: 
    - inventory_hostname == groups['galera'][0]
    - cluster_status.stdout is defined
    - cluster_status.stdout == "Initialized"
  # This acts like your manual restart by forcing db-01 to form a Primary Component

- name: "[Gatekeeper] Final Wait for Sync after Recovery"
  shell: |
    PASS="{{ wsrep_sst_auth.split(':')[1] }}"
    mariadb -u root -p"$PASS" -N -s -e "SHOW STATUS LIKE 'wsrep_local_state_comment';" | awk '{print $2}'
  become: yes
  register: final_sync_check
  until: final_sync_check.stdout == "Synced" or final_sync_check.stdout == "Standalone"
  retries: 15
  delay: 10
  when: 
    - cluster_status.stdout is defined 
    - cluster_status.stdout != "Synced"
    - cluster_status.stdout != "Standalone"

- name: Create MariaDB Exporter User
  community.mysql.mysql_user:
    name: "exporter"
    password: "{{ exporter_password }}"
    priv: "*.*:PROCESS,REPLICATION CLIENT,SELECT"
    state: present
    column_case_sensitive: false 
    # --- FIX FOR IDEMPOTENCY ---
    login_user: root
    login_password: "{{ wsrep_sst_auth.split(':')[1] }}"
    login_unix_socket: /var/run/mysqld/mysqld.sock
    check_implicit_admin: yes
    # ---------------------------
  become: yes
  # Apply to Galera nodes and the Async node
  when: inventory_hostname in (groups['galera'] + groups['async'] | default([]))

- name: Configure MySQL Exporter Auth
  copy:
    dest: /etc/mysql/exporter.cnf
    owner: prometheus
    group: prometheus
    mode: '0400'
    content: |
      [client]
      user=exporter
      password={{ exporter_password }}
      host=localhost
  become: yes
  register: exporter_cfg
  when: inventory_hostname in (groups['galera'] + groups['async'] | default([]))

- name: Set MySQL Exporter Flags
  lineinfile:
    path: /etc/default/prometheus-mysqld-exporter
    regexp: '^ARGS='
    line: 'ARGS="--config.my-cnf=/etc/mysql/exporter.cnf --web.listen-address=:9104"'
  become: yes
  register: exporter_flags
  when: inventory_hostname in (groups['galera'] + groups['async'] | default([]))

- name: Restart and Enable Monitoring Agents
  systemd:
    name: "{{ item }}"
    state: restarted
    enabled: yes
    daemon_reload: yes
  become: yes
  loop:
    - prometheus-node-exporter
    - prometheus-mysqld-exporter
  # Only restart if the config actually changed to avoid unnecessary downtime
  when: 
    - inventory_hostname in (groups['galera'] + groups['async'] | default([]))
    - exporter_cfg.changed or exporter_flags.changed

- name: Ensure Node Exporter is active on non-DB nodes
  systemd:
    name: prometheus-node-exporter
    state: started
    enabled: yes
  become: yes
  when: inventory_hostname not in (groups['galera'] + groups['async'] | default([]))
